{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from joblib import Parallel, delayed\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# # ===============================================================\n",
    "# # Updated per-domain matching with embeddings + cluster features\n",
    "# # ===============================================================\n",
    "\n",
    "# def process_one_domain(domain, resume_df, job_posts_df, resume_embeddings, job_embeddings):\n",
    "#     domain_resumes = resume_df[resume_df[\"ClusterDomainLabel\"] == domain]\n",
    "#     domain_jobs = job_posts_df[job_posts_df[\"ClusterDomainLabel\"] == domain]\n",
    "#     results = []\n",
    "\n",
    "#     if domain_jobs.empty or domain_resumes.empty:\n",
    "#         return results\n",
    "\n",
    "#     print(f\"Processing domain: {domain} ({len(domain_jobs)} jobs × {len(domain_resumes)} resumes)\")\n",
    "\n",
    "#     for j_idx, job_row in domain_jobs.iterrows():\n",
    "#         job_text = job_row[\"job_text_clean\"]\n",
    "#         j_emb = job_embeddings[j_idx]\n",
    "#         job_cluster = job_row[\"PredictedCluster\"]\n",
    "#         job_domain = job_row[\"ClusterDomainLabel\"]\n",
    "\n",
    "#         for r_idx, resume_row in domain_resumes.iterrows():\n",
    "#             resume_text = resume_row[\"Resume_clean\"]\n",
    "#             r_emb = resume_embeddings[r_idx]\n",
    "#             resume_cluster = resume_row[\"PredictedCluster\"]\n",
    "#             resume_domain = resume_row[\"ClusterDomainLabel\"]\n",
    "\n",
    "#             # --- Semantic cosine similarity ---\n",
    "#             cos_sim = cosine_similarity([r_emb], [j_emb])[0][0]\n",
    "\n",
    "#             # --- Hybrid composite scoring ---\n",
    "#             final_score, components = calculate_composite_score(\n",
    "#                 resume_text, job_text,\n",
    "#                 r_emb, j_emb,\n",
    "#                 resume_cluster, job_cluster,\n",
    "#                 resume_domain, job_domain\n",
    "#             )\n",
    "\n",
    "#             results.append({\n",
    "#                 \"resume_id\": resume_row.get(\"ID\", r_idx),\n",
    "#                 \"job_id\": job_row.get(\"ID\", j_idx),\n",
    "#                 \"resume_cluster\": resume_cluster,\n",
    "#                 \"job_cluster\": job_cluster,\n",
    "#                 \"same_cluster\": int(resume_cluster == job_cluster),\n",
    "#                 \"resume_domain\": resume_domain,\n",
    "#                 \"job_domain\": job_domain,\n",
    "#                 \"same_domain\": 1,  # all are domain-aligned here\n",
    "#                 \"cosine_similarity\": cos_sim,\n",
    "#                 **components,\n",
    "#                 \"final_score\": final_score\n",
    "#             })\n",
    "#     return results\n",
    "\n",
    "\n",
    "# # ===============================================================\n",
    "# # Parallel wrapper for all domains\n",
    "# # ===============================================================\n",
    "# def generate_training_pairs_parallel(resume_df, job_posts_df, resume_embeddings, job_embeddings):\n",
    "#     domains = sorted(set(resume_df[\"ClusterDomainLabel\"]) & set(job_posts_df[\"ClusterDomainLabel\"]))\n",
    "    \n",
    "#     all_results = Parallel(n_jobs=-1, backend=\"loky\")(\n",
    "#         delayed(process_one_domain)(domain, resume_df, job_posts_df, resume_embeddings, job_embeddings)\n",
    "#         for domain in domains\n",
    "#     )\n",
    "\n",
    "#     pairs_flat = [x for sublist in all_results for x in sublist]\n",
    "#     training_pairs = pd.DataFrame(pairs_flat)\n",
    "#     print(f\"\\n✅ Generated {len(training_pairs):,} resume–job pairs across {len(domains)} domains.\")\n",
    "#     return training_pairs\n",
    "\n",
    "\n",
    "# # ===============================================================\n",
    "# # Run the generator\n",
    "# # ===============================================================\n",
    "# training_pairs = generate_training_pairs_parallel(\n",
    "#     resumes_filtered, jobs_filtered, resume_embeddings, job_embeddings\n",
    "# )\n",
    "\n",
    "# # training_pairs = generate_training_pairs_parallel(resume_df, job_posts_df, resume_embeddings, job_embeddings)\n",
    "\n",
    "# # ===============================================================\n",
    "# # Labeling: 3 classes (good / medium / poor)\n",
    "# # ===============================================================\n",
    "# scores = training_pairs[\"final_score\"]\n",
    "# high_t = scores.quantile(0.75)\n",
    "# low_t = scores.quantile(0.25)\n",
    "\n",
    "# def assign_label(score):\n",
    "#     if score >= high_t:\n",
    "#         return 1          # good fit\n",
    "#     elif score <= low_t:\n",
    "#         return 0          # poor fit\n",
    "#     else:\n",
    "#         return 0.5        # medium fit\n",
    "\n",
    "# training_pairs[\"label\"] = scores.apply(assign_label)\n",
    "# print(f\"Label thresholds: High ≥ {high_t:.3f}, Low ≤ {low_t:.3f}\")\n",
    "\n",
    "# # ===============================================================\n",
    "# # Save and visualize\n",
    "# # ===============================================================\n",
    "# out_path = os.path.join(DATA_DIR, \"resume_job_training_data.csv\")\n",
    "# training_pairs.to_csv(out_path, index=False)\n",
    "# print(f\"✅ Saved labeled training data → {out_path}\")\n",
    "\n",
    "# # import matplotlib.pyplot as plt\n",
    "# # plt.figure(figsize=(8,5))\n",
    "# # plt.hist(training_pairs[\"final_score\"], bins=30, color='skyblue', edgecolor='black')\n",
    "# # plt.title(\"Distribution of Resume–Job Final Fit Scores\")\n",
    "# # plt.xlabel(\"Final Score\")\n",
    "# # plt.ylabel(\"Frequency\")\n",
    "# # plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
