{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Imports & Paths\n",
    "import importlib.util\n",
    "import os, sys, re, pandas as pd\n",
    "sys.path.append(os.path.join(os.pardir, \"utils\"))\n",
    "\n",
    "DATA_DIR = os.path.join(os.pardir, \"data\")\n",
    "resume_path = os.path.join(DATA_DIR, \"resumes_cleaned.csv\")\n",
    "jobs_path   = os.path.join(DATA_DIR, \"jobs_cleaned.csv\")\n",
    "\n",
    "\n",
    "EMB_DIR = os.path.join(os.pardir, \"data/embeddings\")\n",
    "remb_path = os.path.join(EMB_DIR, \"resume_embeddings.npy\")\n",
    "jemb_path   = os.path.join(EMB_DIR, \"job_embeddings.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_df = pd.read_csv(resume_path)\n",
    "job_posts_df = pd.read_csv(jobs_path)\n",
    "resume_embeddings = np.load(remb_path)\n",
    "job_embeddings = np.load(jemb_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def domain_score_vector(text, domain_keywords=DOMAIN_KEYWORDS_REFERENCE):\n",
    "    text_lower = str(text).lower()\n",
    "    return {\n",
    "        domain: sum(kw in text_lower for kw in keywords)\n",
    "        for domain, keywords in domain_keywords.items()\n",
    "    }\n",
    "\n",
    "def detect_domain(text, domain_keywords=DOMAIN_KEYWORDS_REFERENCE):\n",
    "    scores = domain_score_vector(text, domain_keywords)\n",
    "    return max(scores, key=scores.get) if max(scores.values()) > 0 else \"other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_domain_vectors = [domain_score_vector(t) for t in resume_df[\"Resume_clean\"]]\n",
    "resume_domain_df = pd.DataFrame(resume_domain_vectors, index=resume_df.index)\n",
    "\n",
    "resume_scaler = MinMaxScaler()\n",
    "resume_domain_scaled = resume_scaler.fit_transform(resume_domain_df)\n",
    "\n",
    "resume_features = np.hstack([resume_embeddings, resume_domain_scaled])\n",
    "\n",
    "kmeans = KMeans(n_clusters=6, random_state=42)\n",
    "resume_labels = kmeans.fit_predict(resume_features)\n",
    "resume_df[\"PredictedCluster\"] = resume_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_cluster_summary = (\n",
    "    resume_df.drop(columns=[\"ID\"], errors=\"ignore\") \n",
    "            .join(resume_domain_df)\n",
    "             .groupby(\"PredictedCluster\")\n",
    "             .mean(numeric_only=True)\n",
    ")\n",
    "\n",
    "print(resume_cluster_summary)\n",
    "\n",
    "domain_cols =  [\"Tech & IT\", \"Finance & Accounting\", \"Business & Sales\", \"Law & Advocacy\", \"Healthcare\", \"HR & Operations\", \"Creative & Design\",\"Education\",\n",
    " \"Manufacturing & Construction\", \"Agriculture & Environment\",\"Hospitality & Food\", \"Other Services\"]\n",
    "# domain_cols = [\"hr\", \"finance\", \"it\", \"sales\", \"administration\", \"research\"]\n",
    "\n",
    "top_domain = resume_cluster_summary[domain_cols].idxmax(axis=1)\n",
    "for c, dom in top_domain.items():\n",
    "    print(f\"Resume Cluster {c}: primarily {dom.upper()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 10. Visualize clusters (PCA 2D) ---\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "reduced = pca.fit_transform(resume_features)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(x=reduced[:,0], y=reduced[:,1], hue=resume_labels, palette=\"tab10\", s=10)\n",
    "plt.title(\"Resume Clusters (Hybrid Embedding + Domain Features)\")\n",
    "plt.legend(title=\"Cluster\")\n",
    "plt.show()\n",
    "\n",
    "# --- 11. Inspect domain distribution per cluster ---\n",
    "domain_labels = [detect_domain(t) for t in resume_df[\"Resume_clean\"]]\n",
    "resume_df[\"domain_label\"] = domain_labels\n",
    "domain_cluster_ct = pd.crosstab(resume_df[\"domain_label\"], resume_df[\"PredictedCluster\"])\n",
    "print(domain_cluster_ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Compute domain features (Jobs) ---\n",
    "job_domain_vectors = [domain_score_vector(t) for t in job_posts_df[\"job_text_clean\"]]\n",
    "job_domain_df = pd.DataFrame(job_domain_vectors, index=job_posts_df.index)\n",
    "\n",
    "# --- Normalize domain scores ---\n",
    "job_scaler = MinMaxScaler()\n",
    "job_domain_scaled = job_scaler.fit_transform(job_domain_df)\n",
    "\n",
    "# --- Combine embeddings + domain features ---\n",
    "job_features = np.hstack([job_embeddings, job_domain_scaled])\n",
    "\n",
    "# --- Cluster ---\n",
    "kmeans_jobs = KMeans(n_clusters=6, random_state=42)\n",
    "job_labels = kmeans_jobs.fit_predict(job_features)\n",
    "job_posts_df[\"PredictedCluster\"] = job_labels\n",
    "\n",
    "# --- Summarize by domain ---\n",
    "domain_cols = [\n",
    "    \"Tech & IT\",\n",
    "    \"Finance & Accounting\",\n",
    "    \"Business & Sales\",\n",
    "    \"Law & Advocacy\",\n",
    "    \"Healthcare\",\n",
    "    \"HR & Operations\",\n",
    "    \"Creative & Design\",\n",
    "    \"Education\",\n",
    "    \"Manufacturing & Construction\",\n",
    "    \"Agriculture & Environment\",\n",
    "    \"Hospitality & Food\",\n",
    "    \"Other Services\"\n",
    "]\n",
    "job_cluster_summary = (\n",
    "    pd.concat([job_posts_df[\"PredictedCluster\"], job_domain_df], axis=1)\n",
    "      .groupby(\"PredictedCluster\")[domain_cols]\n",
    "      .mean()\n",
    ")\n",
    "print(job_cluster_summary.round(2))\n",
    "\n",
    "# --- Identify top domain per job cluster ---\n",
    "top_domain = job_cluster_summary[domain_cols].idxmax(axis=1)\n",
    "for c, dom in top_domain.items():\n",
    "    print(f\"Job Cluster {c}: primarily {dom.upper()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2, random_state=42)\n",
    "job_reduced = pca.fit_transform(job_features)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(job_reduced[:,0], job_reduced[:,1],\n",
    "            c=job_labels, cmap='tab10', s=10)\n",
    "plt.title(\"Job Post Clusters (Hybrid Embedding + Domain Features)\")\n",
    "plt.show()\n",
    "\n",
    "# --- Save clustered data with standardized columns ---\n",
    "# Add PCA coordinates for visualization\n",
    "pca_resume = PCA(n_components=2, random_state=42)\n",
    "resume_pca = pca_resume.fit_transform(resume_features)\n",
    "resume_df[\"PCA_X\"] = resume_pca[:, 0]\n",
    "resume_df[\"PCA_Y\"] = resume_pca[:, 1]\n",
    "\n",
    "pca_job = PCA(n_components=2, random_state=42)\n",
    "job_pca = pca_job.fit_transform(job_features)\n",
    "job_posts_df[\"PCA_X\"] = job_pca[:, 0]\n",
    "job_posts_df[\"PCA_Y\"] = job_pca[:, 1]\n",
    "\n",
    "# Assign domain labels to clusters\n",
    "resume_cluster_domain_map = resume_cluster_summary[domain_cols].idxmax(axis=1)\n",
    "job_cluster_domain_map = job_cluster_summary[domain_cols].idxmax(axis=1)\n",
    "\n",
    "resume_df[\"ClusterDomainLabel\"] = resume_df[\"PredictedCluster\"].map(resume_cluster_domain_map)\n",
    "job_posts_df[\"JobClusterDomainLabel\"] = job_posts_df[\"PredictedCluster\"].map(job_cluster_domain_map)\n",
    "\n",
    "# Save standardized outputs\n",
    "resume_output_path = os.path.join(DATA_DIR, \"resumes_clustered_hybrid.csv\")\n",
    "job_output_path = os.path.join(DATA_DIR, \"jobs_clustered_hybrid.csv\")\n",
    "\n",
    "resume_df.to_csv(resume_output_path, index=False)\n",
    "job_posts_df.to_csv(job_output_path, index=False)\n",
    "\n",
    "print(f\"✅ Saved clustered resumes to {resume_output_path}\")\n",
    "print(f\"✅ Saved clustered jobs to {job_output_path}\")\n",
    "print(f\"\\nResume columns: {list(resume_df.columns)}\")\n",
    "print(f\"Job columns: {list(job_posts_df.columns)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
