{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Imports & Paths\n",
    "import importlib.util\n",
    "import os, sys, re, pandas as pd\n",
    "sys.path.append(os.path.join(os.pardir, \"utils\"))\n",
    "\n",
    "DATA_DIR = os.path.join(os.pardir, \"data\")\n",
    "resume_path = os.path.join(DATA_DIR, \"resumes_cleaned.csv\")\n",
    "jobs_path   = os.path.join(DATA_DIR, \"jobs_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load Data\n",
    "resume_df = pd.read_csv(resume_path)\n",
    "job_posts_df = pd.read_csv(jobs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_lengths = resume_df['Resume_str'].str.len()\n",
    "job_lengths = job_posts_df['JobDescription'].str.len()\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "ax1.hist(resume_lengths, bins=50, alpha=0.7)\n",
    "ax1.set_title('Resume Text Length Distribution')\n",
    "ax1.set_xlabel('Character Count')\n",
    "\n",
    "ax2.hist(job_lengths, bins=50, alpha=0.7)\n",
    "ax2.set_title('Job Description Length Distribution')\n",
    "ax2.set_xlabel('Character Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get most common words in resumes and job postings\n",
    "def get_top_words(text_series, n=45):\n",
    "    all_words = ' '.join(text_series).lower().split()\n",
    "    # Remove stopwords and short words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_words = [word for word in all_words if word not in stop_words and len(word) > 2]\n",
    "    return Counter(filtered_words).most_common(n)\n",
    "\n",
    "top_resume_words = get_top_words(resume_df['Resume_str'])\n",
    "top_job_words = get_top_words(job_posts_df['JobDescription'])\n",
    "print(top_resume_words)\n",
    "print(top_job_words)\n",
    "# Plot word frequencies\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "words, counts = zip(*top_resume_words)\n",
    "ax1.barh(words, counts)\n",
    "ax1.set_title('Top Words in Resumes')\n",
    "\n",
    "words, counts = zip(*top_job_words)\n",
    "ax2.barh(words, counts)\n",
    "ax2.set_title('Top Words in Job Descriptions')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common skills extraction (simplified)\n",
    "# Add/update list with keywords we are interested in\n",
    "skills_keywords = ['python', 'java', 'sql', 'machine learning', 'aws',\n",
    "                   'docker', 'kubernetes', 'react', 'node.js', 'tensorflow']\n",
    "\n",
    "def count_skills(text, skills_list):\n",
    "    text_lower = text.lower()\n",
    "    return sum(1 for skill in skills_list if skill in text_lower)\n",
    "\n",
    "# Count skills in resumes and job postings\n",
    "for skill in skills_keywords:\n",
    "    resume_df[f'resume_has_{skill}'] = resume_df['Resume_str'].str.lower().str.contains(skill)\n",
    "    job_posts_df[f'job_has_{skill}'] = job_posts_df['JobDescription'].str.lower().str.contains(skill)\n",
    "\n",
    "# Plot skills frequency\n",
    "resume_skills_count = resume_df[[f'resume_has_{skill}' for skill in skills_keywords]].sum()\n",
    "job_skills_count = job_posts_df[[f'job_has_{skill}' for skill in skills_keywords]].sum()\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "resume_skills_count.plot(kind='barh', ax=ax1)\n",
    "ax1.set_title('Skills Frequency in Resumes')\n",
    "job_skills_count.plot(kind='barh', ax=ax2)\n",
    "ax2.set_title('Skills Frequency in Job Postings')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bigram analysis\n",
    "def plot_top_ngrams(text_series, n=2, top_k=45):\n",
    "    vectorizer = CountVectorizer(ngram_range=(n, n), stop_words='english',\n",
    "                               max_features=top_k)\n",
    "    X = vectorizer.fit_transform(text_series)\n",
    "    words = vectorizer.get_feature_names_out()\n",
    "    counts = X.sum(axis=0).A1\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(words, counts)\n",
    "    plt.title(f'Top {n}-grams')\n",
    "    plt.show()\n",
    "\n",
    "# Compare bigrams in resumes vs job postings\n",
    "plot_top_ngrams(resume_df['Resume_str'], n=2)\n",
    "plot_top_ngrams(job_posts_df['JobDescription'], n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_keywords_in_series(text_series, domain_keywords):\n",
    "    \"\"\"Counts all domain keywords in a pandas Series of text efficiently.\"\"\"\n",
    "    domain_counts = {domain: 0 for domain in domain_keywords}\n",
    "    keyword_counts = Counter()\n",
    "    \n",
    "    for domain, keywords in domain_keywords.items():\n",
    "        for kw in keywords:\n",
    "            # Build a regex for full word or phrase match (case-insensitive)\n",
    "            pattern = rf'\\b{re.escape(kw.lower())}\\b'\n",
    "            # Sum counts across all rows\n",
    "            count = text_series.str.count(pattern, flags=re.IGNORECASE).sum()\n",
    "            if count > 0:\n",
    "                domain_counts[domain] += count\n",
    "                keyword_counts[(domain, kw)] += count\n",
    "                \n",
    "    return domain_counts, keyword_counts\n",
    "\n",
    "resume_domain_counts, resume_kw_counts = count_keywords_in_series(resume_df['Resume_str'], domain_keywords)\n",
    "job_domain_counts, job_kw_counts = count_keywords_in_series(job_posts_df['job_text'], domain_keywords)\n",
    "\n",
    "\n",
    "domain_summary = pd.DataFrame({\n",
    "    'domain': list(domain_keywords.keys()),\n",
    "    'resume_keyword_count': [resume_domain_counts[d] for d in domain_keywords],\n",
    "    'job_keyword_count': [job_domain_counts[d] for d in domain_keywords]\n",
    "}).sort_values(by='resume_keyword_count', ascending=False)\n",
    "\n",
    "# Optional: detailed keyword-level breakdown\n",
    "resume_kw_df = pd.DataFrame(resume_kw_counts.items(), columns=['(domain, keyword)', 'resume_count'])\n",
    "job_kw_df = pd.DataFrame(job_kw_counts.items(), columns=['(domain, keyword)', 'job_count'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show top 10 keywords by count\n",
    "print(\"=== Resume Keyword Counts (Top 30) ===\")\n",
    "display(resume_kw_df.sort_values('resume_count', ascending=False).head(30))\n",
    "\n",
    "print(\"=== Job Keyword Counts (Top 30) ===\")\n",
    "display(job_kw_df.sort_values('job_count', ascending=False).head(30))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"=== Domain-Level Keyword Summary ===\")\n",
    "print(domain_summary, \"\\n\")\n",
    "\n",
    "print(\"=== Sample Keyword-Level Breakdown (Top 10) ===\")\n",
    "print(resume_kw_df.sort_values('resume_count', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_compare = pd.merge(\n",
    "    resume_kw_df, job_kw_df,\n",
    "    on='(domain, keyword)', how='outer'\n",
    ").fillna(0)\n",
    "\n",
    "kw_compare['difference'] = kw_compare['resume_count'] - kw_compare['job_count']\n",
    "\n",
    "# Show top 20 overrepresented in resumes\n",
    "kw_compare.sort_values('difference', ascending=False).head(20)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
