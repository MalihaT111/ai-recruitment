{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb75280a",
   "metadata": {},
   "source": [
    "# ðŸš€ BERT Resume-Job Matcher Training\n",
    "\n",
    "## âš¡ Quick Start - Dealing with Large Datasets\n",
    "\n",
    "**If training is too slow:** \n",
    "1. **Interrupt the kernel** (stop button)\n",
    "2. Adjust `SAMPLE_SIZE` in **Cell 7** (currently 10,000)\n",
    "   - For quick testing: 5,000 samples (~2-3 hours)\n",
    "   - For balanced training: 10,000 samples (~4-6 hours)\n",
    "   - For better accuracy: 20,000 samples (~8-12 hours)\n",
    "3. **Rerun from Cell 7** onwards\n",
    "\n",
    "The notebook will automatically sample your data to make training feasible while maintaining label distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d45e455",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments, \n",
    "    Trainer\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63385fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.8.0+cpu\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(os.path.join(os.pardir, \"utils\"))\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6cbd7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from utils import *\n",
    "\n",
    "# Paths\n",
    "DATA_DIR = os.path.join(os.pardir, \"data\")\n",
    "CLUSTER_DIR = os.path.join(DATA_DIR, \"clusters\")\n",
    "EMB_DIR = os.path.join(DATA_DIR, \"embeddings\")\n",
    "OUTPUT_DIR = os.path.join(os.pardir, \"data_outputs\")\n",
    "MODEL_DIR = os.path.join(os.pardir, \"models\", \"bert_resume_matcher\")\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "# File paths\n",
    "resume_path = os.path.join(CLUSTER_DIR, \"resumes_clustered.csv\")\n",
    "jobs_path = os.path.join(CLUSTER_DIR, \"jobs_clustered.csv\")\n",
    "resume_emb_path = os.path.join(EMB_DIR, \"resume_embeddings.npy\")\n",
    "job_emb_path = os.path.join(EMB_DIR, \"job_embeddings.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35a4be5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded 2484 resumes and 5448 jobs\n",
      "âœ… Embeddings: (2484, 384), (5448, 384)\n",
      "\n",
      "Resume columns: ['ID', 'Resume_str', 'Resume_html', 'Category', 'Resume_clean', 'DomainCluster', 'PredictedCluster', 'x', 'y', 'KeywordDomain', 'ClusterDomainLabel']\n",
      "Job columns: ['jobpost', 'date', 'Title', 'Company', 'Location', 'JobDescription', 'JobRequirment', 'RequiredQual', 'Salary', 'ApplicationP', 'AboutC', 'Year', 'Month', 'IT', 'job_text', 'job_text_clean', 'PredictedCluster', 'KeywordDomain', 'ClusterDomainLabel', 'DomainCluster', 'x', 'y']\n"
     ]
    }
   ],
   "source": [
    "resumes = pd.read_csv(resume_path)\n",
    "jobs = pd.read_csv(jobs_path)\n",
    "resume_embeddings = np.load(resume_emb_path)\n",
    "job_embeddings = np.load(job_emb_path)\n",
    "\n",
    "print(f\"âœ… Loaded {len(resumes)} resumes and {len(jobs)} jobs\")\n",
    "print(f\"âœ… Embeddings: {resume_embeddings.shape}, {job_embeddings.shape}\")\n",
    "print(f\"\\nResume columns: {resumes.columns.tolist()}\")\n",
    "print(f\"Job columns: {jobs.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8aa8833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Generating training pairs across all domains...\n",
      "Domains to process: ['Creative & Design', 'Education', 'Finance & Accounting', 'Other Services', 'Tech & IT']\n",
      "Processing domain: Creative & Design (175 jobs Ã— 268 resumes)\n",
      "Processing domain: Education (833 jobs Ã— 174 resumes)\n",
      "Processing domain: Education (833 jobs Ã— 174 resumes)\n",
      "Processing domain: Finance & Accounting (772 jobs Ã— 594 resumes)\n",
      "Processing domain: Finance & Accounting (772 jobs Ã— 594 resumes)\n",
      "Processing domain: Other Services (1417 jobs Ã— 273 resumes)\n",
      "Processing domain: Other Services (1417 jobs Ã— 273 resumes)\n",
      "Processing domain: Tech & IT (2251 jobs Ã— 213 resumes)\n",
      "Processing domain: Tech & IT (2251 jobs Ã— 213 resumes)\n",
      "\n",
      "âœ… Generated 1,516,714 resume-job pairs\n",
      "\n",
      "âœ… Generated 1,516,714 resume-job pairs\n"
     ]
    }
   ],
   "source": [
    "def calculate_composite_score(resume_text, job_text, resume_emb, job_emb,\n",
    "                              resume_cluster, job_cluster, resume_domain, job_domain):\n",
    "    \"\"\"\n",
    "    Calculate a composite matching score between resume and job.\n",
    "    Returns final_score (0-1) and component scores dict.\n",
    "    \"\"\"\n",
    "    # Semantic similarity (0-1)\n",
    "    semantic_sim = float(cosine_similarity([resume_emb], [job_emb])[0][0])\n",
    "    semantic_sim = max(0, min(1, semantic_sim))  # Clip to [0,1]\n",
    "    \n",
    "    # Domain match bonus\n",
    "    domain_score = 1.0 if resume_domain == job_domain else 0.3\n",
    "    \n",
    "    # Cluster match bonus\n",
    "    cluster_score = 1.0 if resume_cluster == job_cluster else 0.5\n",
    "    \n",
    "    # Simple keyword overlap (basic skills matching)\n",
    "    resume_words = set(str(resume_text).lower().split())\n",
    "    job_words = set(str(job_text).lower().split())\n",
    "    \n",
    "    common_words = resume_words & job_words\n",
    "    keyword_score = min(len(common_words) / max(len(job_words), 1), 1.0) if job_words else 0\n",
    "    \n",
    "    # Weighted combination\n",
    "    final_score = (\n",
    "        0.40 * semantic_sim +\n",
    "        0.25 * domain_score +\n",
    "        0.20 * cluster_score +\n",
    "        0.15 * keyword_score\n",
    "    )\n",
    "    \n",
    "    # Ensure in [0,1]\n",
    "    final_score = max(0, min(1, final_score))\n",
    "    \n",
    "    components = {\n",
    "        'semantic_score': semantic_sim,\n",
    "        'domain_score': domain_score,\n",
    "        'cluster_score': cluster_score,\n",
    "        'keyword_score': keyword_score\n",
    "    }\n",
    "    \n",
    "    return final_score, components\n",
    "\n",
    "\n",
    "def process_one_domain(domain, resumes, jobs, resume_embeddings, job_embeddings):\n",
    "    \"\"\"Process resume-job pairs within a single domain\"\"\"\n",
    "    domain_resumes = resumes[resumes[\"ClusterDomainLabel\"] == domain]\n",
    "    domain_jobs = jobs[jobs[\"ClusterDomainLabel\"] == domain]\n",
    "    results = []\n",
    "    \n",
    "    if domain_jobs.empty or domain_resumes.empty:\n",
    "        return results\n",
    "    \n",
    "    print(f\"Processing domain: {domain} ({len(domain_jobs)} jobs Ã— {len(domain_resumes)} resumes)\")\n",
    "    \n",
    "    for j_idx, job_row in domain_jobs.iterrows():\n",
    "        j_emb = job_embeddings[j_idx]\n",
    "        job_cluster = job_row.get(\"PredictedCluster\", -1)\n",
    "        job_domain = job_row[\"ClusterDomainLabel\"]\n",
    "        \n",
    "        for r_idx, resume_row in domain_resumes.iterrows():\n",
    "            r_emb = resume_embeddings[r_idx]\n",
    "            resume_cluster = resume_row.get(\"PredictedCluster\", -1)\n",
    "            resume_domain = resume_row[\"ClusterDomainLabel\"]\n",
    "            \n",
    "            # Semantic similarity\n",
    "            cos_sim = cosine_similarity([r_emb], [j_emb])[0][0]\n",
    "\n",
    "            # Composite scoring\n",
    "            final_score, components = calculate_composite_score(\n",
    "                resume_row[\"Resume_clean\"],\n",
    "                job_row[\"job_text_clean\"],\n",
    "                r_emb, j_emb,\n",
    "                resume_cluster, job_cluster,\n",
    "                resume_domain, job_domain\n",
    "            )\n",
    "            \n",
    "            result = {\n",
    "                \"resume_id\": resume_row.get(\"ID\", r_idx),\n",
    "                \"job_id\": j_idx,\n",
    "                \"resume_text\": resume_row[\"Resume_clean\"],\n",
    "                \"job_text\": job_row[\"job_text_clean\"],\n",
    "                \"resume_domain\": resume_domain,\n",
    "                \"job_domain\": job_domain,\n",
    "                \"cosine_similarity\": cos_sim,\n",
    "                \"final_score\": final_score,\n",
    "                \"same_cluster\": int(resume_cluster == job_cluster),\n",
    "                \"same_domain\": 1,\n",
    "                **components\n",
    "            }\n",
    "            results.append(result)\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"ðŸš€ Generating training pairs across all domains...\")\n",
    "domains = sorted(set(resumes[\"ClusterDomainLabel\"]) & set(jobs[\"ClusterDomainLabel\"]))\n",
    "print(f\"Domains to process: {domains}\")\n",
    "\n",
    "# Use threading instead of multiprocessing to avoid serialization issues\n",
    "all_results = []\n",
    "for domain in domains:\n",
    "    domain_results = process_one_domain(domain, resumes, jobs, resume_embeddings, job_embeddings)\n",
    "    all_results.append(domain_results)\n",
    "\n",
    "pairs_flat = [x for sublist in all_results for x in sublist]\n",
    "training_pairs = pd.DataFrame(pairs_flat)\n",
    "\n",
    "print(f\"\\nâœ… Generated {len(training_pairs):,} resume-job pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2f29202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score statistics:\n",
      "count    1.516714e+06\n",
      "mean     6.162329e-01\n",
      "std      6.408095e-02\n",
      "min      3.500000e-01\n",
      "25%      5.726662e-01\n",
      "50%      6.180735e-01\n",
      "75%      6.594195e-01\n",
      "max      8.539293e-01\n",
      "Name: final_score, dtype: float64\n",
      "\n",
      "Label distribution:\n",
      "label_category\n",
      "medium    758356\n",
      "poor      379179\n",
      "good      379179\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Label distribution:\n",
      "label_category\n",
      "medium    758356\n",
      "poor      379179\n",
      "good      379179\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use final_score as continuous target (0-1 range)\n",
    "scores = training_pairs[\"final_score\"]\n",
    "print(f\"Score statistics:\")\n",
    "print(scores.describe())\n",
    "\n",
    "# Create categorical labels for analysis\n",
    "high_t = scores.quantile(0.75)\n",
    "low_t = scores.quantile(0.25)\n",
    "\n",
    "def assign_label_category(score):\n",
    "    if score >= high_t:\n",
    "        return \"good\"\n",
    "    elif score <= low_t:\n",
    "        return \"poor\"\n",
    "    else:\n",
    "        return \"medium\"\n",
    "\n",
    "training_pairs[\"label_category\"] = scores.apply(assign_label_category)\n",
    "training_pairs[\"label\"] = training_pairs[\"final_score\"]  # Use continuous score\n",
    "\n",
    "print(f\"\\nLabel distribution:\")\n",
    "print(training_pairs[\"label_category\"].value_counts())\n",
    "\n",
    "# Visualize score distribution\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(training_pairs[\"label\"], bins=50, edgecolor='black')\n",
    "plt.axvline(high_t, color='g', linestyle='--', label=f'High threshold ({high_t:.2f})')\n",
    "plt.axvline(low_t, color='r', linestyle='--', label=f'Low threshold ({low_t:.2f})')\n",
    "plt.xlabel(\"Final Score\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Resume-Job Match Scores\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca63f860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved full training data â†’ ..\\data_outputs\\resume_job_training_data.csv\n",
      "âœ… Saved BERT dataset â†’ ..\\data_outputs\\bert_finetuning_dataset.csv\n",
      "   Shape: (1515881, 3)\n",
      "âœ… Saved BERT dataset â†’ ..\\data_outputs\\bert_finetuning_dataset.csv\n",
      "   Shape: (1515881, 3)\n"
     ]
    }
   ],
   "source": [
    "full_path = os.path.join(OUTPUT_DIR, \"resume_job_training_data.csv\")\n",
    "training_pairs.to_csv(full_path, index=False)\n",
    "print(f\"âœ… Saved full training data â†’ {full_path}\")\n",
    "\n",
    "# Create BERT-ready dataset\n",
    "bert_dataset = training_pairs[[\"resume_text\", \"job_text\", \"label\"]].copy()\n",
    "bert_dataset = bert_dataset.dropna()\n",
    "bert_dataset[\"label\"] = bert_dataset[\"label\"].clip(0, 1)\n",
    "\n",
    "# ðŸ”¥ SAMPLE DATA TO MAKE TRAINING FEASIBLE ðŸ”¥\n",
    "# Take a stratified sample to keep label distribution\n",
    "SAMPLE_SIZE = 10000  # Adjust this number based on your needs (5k-20k recommended)\n",
    "\n",
    "if len(bert_dataset) > SAMPLE_SIZE:\n",
    "    print(f\"\\nâš¡ Sampling {SAMPLE_SIZE:,} pairs from {len(bert_dataset):,} total pairs...\")\n",
    "    \n",
    "    # Stratified sampling based on label quantiles to maintain distribution\n",
    "    bert_dataset['label_bin'] = pd.qcut(bert_dataset['label'], q=5, labels=False, duplicates='drop')\n",
    "    bert_dataset_sampled = bert_dataset.groupby('label_bin', group_keys=False).apply(\n",
    "        lambda x: x.sample(min(len(x), SAMPLE_SIZE // 5), random_state=42)\n",
    "    )\n",
    "    bert_dataset_sampled = bert_dataset_sampled.drop('label_bin', axis=1)\n",
    "    bert_dataset = bert_dataset_sampled.reset_index(drop=True)\n",
    "    \n",
    "    print(f\"âœ… Sampled dataset size: {len(bert_dataset):,}\")\n",
    "    print(f\"   Score range: [{bert_dataset['label'].min():.3f}, {bert_dataset['label'].max():.3f}]\")\n",
    "    print(f\"   Score mean: {bert_dataset['label'].mean():.3f}\")\n",
    "else:\n",
    "    print(f\"âœ… Dataset size is manageable: {len(bert_dataset):,}\")\n",
    "\n",
    "bert_path = os.path.join(OUTPUT_DIR, \"bert_finetuning_dataset.csv\")\n",
    "bert_dataset.to_csv(bert_path, index=False)\n",
    "print(f\"âœ… Saved BERT dataset â†’ {bert_path}\")\n",
    "print(f\"   Shape: {bert_dataset.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42ba61bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 1,061,116 samples\n",
      "Validation set: 227,382 samples\n",
      "Test set: 227,383 samples\n"
     ]
    }
   ],
   "source": [
    "train_df, temp_df = train_test_split(bert_dataset, test_size=0.3, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"Train set: {len(train_df):,} samples\")\n",
    "print(f\"Validation set: {len(val_df):,} samples\")\n",
    "print(f\"Test set: {len(test_df):,} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da628789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dataset class defined\n"
     ]
    }
   ],
   "source": [
    "class ResumeJobDataset(Dataset):\n",
    "    \"\"\"Custom dataset for resume-job matching\"\"\"\n",
    "    \n",
    "    def __init__(self, dataframe, tokenizer, max_length=512):\n",
    "        self.data = dataframe.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        \n",
    "        # Combine resume and job text with [SEP] token\n",
    "        text = f\"{row['resume_text']} [SEP] {row['job_text']}\"\n",
    "        \n",
    "        # Tokenize\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(row['label'], dtype=torch.float)\n",
    "        }\n",
    "print(\"âœ… Dataset class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73f10b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading bert-base-uncased...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model loaded: bert\n",
      "   Parameters: 109,483,009\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"bert-base-uncased\"  # or \"roberta-base\"\n",
    "\n",
    "print(f\"Loading {MODEL_NAME}...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# For regression task (predicting similarity score)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=1,  # Regression task\n",
    "    problem_type=\"regression\"\n",
    ")\n",
    "\n",
    "print(f\"âœ… Model loaded: {model.config.model_type}\")\n",
    "print(f\"   Parameters: {model.num_parameters():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "efd5fd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Datasets created\n",
      "   Sample input shape: torch.Size([512])\n",
      "   Sample label: 0.6301\n",
      "   Sample input shape: torch.Size([512])\n",
      "   Sample label: 0.6301\n"
     ]
    }
   ],
   "source": [
    "train_dataset = ResumeJobDataset(train_df, tokenizer, max_length=512)\n",
    "val_dataset = ResumeJobDataset(val_df, tokenizer, max_length=512)\n",
    "test_dataset = ResumeJobDataset(test_df, tokenizer, max_length=512)\n",
    "\n",
    "print(\"âœ… Datasets created\")\n",
    "print(f\"   Sample input shape: {train_dataset[0]['input_ids'].shape}\")\n",
    "print(f\"   Sample label: {train_dataset[0]['labels'].item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96ae2e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Training arguments configured\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=MODEL_DIR,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=500,\n",
    "    logging_dir=os.path.join(MODEL_DIR, 'logs'),\n",
    "    logging_steps=100,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    report_to=\"none\",\n",
    "    fp16=torch.cuda.is_available(),\n",
    ")\n",
    "\n",
    "print(\"âœ… Training arguments configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6a594d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Metrics function defined\n"
     ]
    }
   ],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Compute regression metrics\"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = predictions.flatten()\n",
    "    \n",
    "    mse = mean_squared_error(labels, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(labels, predictions)\n",
    "    \n",
    "    return {\n",
    "        'mse': mse,\n",
    "        'rmse': rmse,\n",
    "        'mae': mae\n",
    "    }\n",
    "\n",
    "print(\"âœ… Metrics function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5ceb500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Trainer initialized\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "print(\"âœ… Trainer initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597e9e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ›‘ STOP CURRENT TRAINING IF RUNNING\n",
    "# If training is taking too long, interrupt the kernel and rerun from cell 7\n",
    "# to apply the sampling\n",
    "\n",
    "print(f\"ðŸ“Š Current dataset sizes:\")\n",
    "print(f\"   Train: {len(train_dataset):,} samples\")\n",
    "print(f\"   Val: {len(val_dataset):,} samples\")\n",
    "print(f\"   Test: {len(test_dataset):,} samples\")\n",
    "print(f\"\\nâ±ï¸ Estimated training time:\")\n",
    "print(f\"   ~{len(train_dataset) * 3 / 3600:.1f} hours for 3 epochs (rough estimate)\")\n",
    "print(f\"\\nðŸ’¡ If this is too long, restart kernel and rerun from cell 7 with smaller SAMPLE_SIZE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cef74bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='163' max='397920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   163/397920 1:39:21 < 4091:09:15, 0.03 it/s, Epoch 0.00/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mðŸš€ Starting training...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m train_result \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mâœ… Training complete!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   Training loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_result\u001b[38;5;241m.\u001b[39mtraining_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\trainer.py:2245\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   2243\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   2244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2245\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2246\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2250\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\trainer.py:2560\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2553\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2554\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[0;32m   2555\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2556\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[0;32m   2557\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[0;32m   2558\u001b[0m )\n\u001b[0;32m   2559\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m-> 2560\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2563\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   2564\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m   2565\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   2566\u001b[0m ):\n\u001b[0;32m   2567\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   2568\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32mc:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\trainer.py:3782\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3779\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED:\n\u001b[0;32m   3780\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale_wrt_gas\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 3782\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3784\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[1;32mc:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\accelerate\\accelerator.py:2454\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[1;34m(self, loss, **kwargs)\u001b[0m\n\u001b[0;32m   2452\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[0;32m   2453\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2454\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\_tensor.py:647\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    638\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    639\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    640\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    645\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    646\u001b[0m     )\n\u001b[1;32m--> 647\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    648\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\__init__.py:354\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    349\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    351\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 354\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    362\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\graph.py:829\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    827\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 829\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    833\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"ðŸš€ Starting training...\")\n",
    "train_result = trainer.train()\n",
    "\n",
    "print(\"\\nâœ… Training complete!\")\n",
    "print(f\"   Training loss: {train_result.training_loss:.4f}\")\n",
    "\n",
    "# Save final model\n",
    "trainer.save_model(MODEL_DIR)\n",
    "tokenizer.save_pretrained(MODEL_DIR)\n",
    "print(f\"âœ… Model saved to: {MODEL_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d8b167",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ“Š Evaluating on test set...\")\n",
    "test_results = trainer.evaluate(test_dataset)\n",
    "\n",
    "print(\"\\nâœ… Test Results:\")\n",
    "for key, value in test_results.items():\n",
    "    print(f\"   {key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99a9ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_match_score(resume_text, job_text, model, tokenizer, device=None):\n",
    "    \"\"\"Predict match score between resume and job\"\"\"\n",
    "    if device is None:\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    # Prepare input\n",
    "    text = f\"{resume_text} [SEP] {job_text}\"\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        max_length=512,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    # Move to device\n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    \n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        score = outputs.logits.item()\n",
    "    \n",
    "    # Clip to 0-1 range\n",
    "    return max(0, min(1, score))\n",
    "\n",
    "print(\"âœ… Prediction function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a13a23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_resume = test_df.iloc[0]['resume_text']\n",
    "sample_job = test_df.iloc[0]['job_text']\n",
    "true_score = test_df.iloc[0]['label']\n",
    "\n",
    "predicted_score = predict_match_score(sample_resume, sample_job, model, tokenizer)\n",
    "\n",
    "print(f\"ðŸ” Sample Prediction:\")\n",
    "print(f\"   True score: {true_score:.4f}\")\n",
    "print(f\"   Predicted score: {predicted_score:.4f}\")\n",
    "print(f\"   Difference: {abs(true_score - predicted_score):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70feb4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ“Š Getting predictions for entire test set...\")\n",
    "test_predictions = trainer.predict(test_dataset)\n",
    "predicted_scores = test_predictions.predictions.flatten()\n",
    "true_scores = test_df['label'].values\n",
    "\n",
    "# Clip predictions to valid range\n",
    "predicted_scores = np.clip(predicted_scores, 0, 1)\n",
    "\n",
    "# Create results dataframe\n",
    "results_df = pd.DataFrame({\n",
    "    'true_score': true_scores,\n",
    "    'predicted_score': predicted_scores,\n",
    "    'error': np.abs(true_scores - predicted_scores)\n",
    "})\n",
    "\n",
    "print(\"\\nâœ… Prediction Statistics:\")\n",
    "print(results_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b741db9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Scatter plot\n",
    "axes[0, 0].scatter(true_scores, predicted_scores, alpha=0.5)\n",
    "axes[0, 0].plot([0, 1], [0, 1], 'r--', label='Perfect prediction')\n",
    "axes[0, 0].set_xlabel('True Score')\n",
    "axes[0, 0].set_ylabel('Predicted Score')\n",
    "axes[0, 0].set_title('True vs Predicted Scores')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Error distribution\n",
    "axes[0, 1].hist(results_df['error'], bins=50, edgecolor='black')\n",
    "axes[0, 1].set_xlabel('Absolute Error')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].set_title(f'Error Distribution (MAE: {results_df[\"error\"].mean():.4f})')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Residuals\n",
    "residuals = true_scores - predicted_scores\n",
    "axes[1, 0].scatter(predicted_scores, residuals, alpha=0.5)\n",
    "axes[1, 0].axhline(y=0, color='r', linestyle='--')\n",
    "axes[1, 0].set_xlabel('Predicted Score')\n",
    "axes[1, 0].set_ylabel('Residual')\n",
    "axes[1, 0].set_title('Residual Plot')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Score distributions\n",
    "axes[1, 1].hist(true_scores, bins=30, alpha=0.5, label='True', edgecolor='black')\n",
    "axes[1, 1].hist(predicted_scores, bins=30, alpha=0.5, label='Predicted', edgecolor='black')\n",
    "axes[1, 1].set_xlabel('Score')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "axes[1, 1].set_title('Score Distributions')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plot_path = os.path.join(MODEL_DIR, 'evaluation_plots.png')\n",
    "plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"âœ… Plots saved to: {plot_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4a9a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_top_k_jobs(resume_text, job_df, model, tokenizer, top_k=5, batch_size=32, device=None):\n",
    "    \"\"\"\n",
    "    Find top-K matching jobs for a given resume using batched inference.\n",
    "    \n",
    "    Args:\n",
    "        resume_text: String containing the resume\n",
    "        job_df: DataFrame with 'job_text' or 'job_text_clean' column\n",
    "        model: Fine-tuned BERT model\n",
    "        tokenizer: Corresponding tokenizer\n",
    "        top_k: Number of top matches to return\n",
    "        batch_size: Batch size for inference\n",
    "        device: 'cuda' or 'cpu'\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with top-K jobs and their match scores\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    # Detect job text column\n",
    "    job_col = None\n",
    "    for col in ['job_text', 'job_text_clean', 'JobDescription']:\n",
    "        if col in job_df.columns:\n",
    "            job_col = col\n",
    "            break\n",
    "    \n",
    "    if job_col is None:\n",
    "        raise ValueError(\"job_df must contain a job text column\")\n",
    "    \n",
    "    job_texts = job_df[job_col].fillna(\"\").astype(str).tolist()\n",
    "    scores = []\n",
    "    \n",
    "    print(f\"ðŸ” Scoring {len(job_texts)} jobs in batches of {batch_size}...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, len(job_texts), batch_size)):\n",
    "            batch_jobs = job_texts[i:i+batch_size]\n",
    "            batch_texts = [f\"{resume_text} [SEP] {jt}\" for jt in batch_jobs]\n",
    "            \n",
    "            encodings = tokenizer(\n",
    "                batch_texts,\n",
    "                max_length=512,\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            \n",
    "            \n",
    "            input_ids = encodings['input_ids'].to(device)\n",
    "            attention_mask = encodings['attention_mask'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            batch_scores = outputs.logits.squeeze(-1).cpu().numpy()\n",
    "            \n",
    "            # Handle single prediction\n",
    "            if batch_scores.ndim == 0:\n",
    "                batch_scores = np.array([float(batch_scores)])\n",
    "            \n",
    "            scores.extend(batch_scores)\n",
    "    \n",
    "    # Clip scores to [0,1]\n",
    "    scores = np.clip(scores, 0, 1)\n",
    "    \n",
    "    # Create results dataframe\n",
    "    results = job_df.copy()\n",
    "    results['match_score'] = scores\n",
    "    results['job_preview'] = results[job_col].str[:200] + '...'\n",
    "    \n",
    "    # Sort and return top-K\n",
    "    top_matches = results.nlargest(top_k, 'match_score')\n",
    "    return top_matches[['match_score', 'job_preview'] + [c for c in ['Title', 'Company', 'Location'] if c in results.columns]]\n",
    "\n",
    "print(\"âœ… Top-K recommendation function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b20874",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_resume_text = resumes.iloc[0]['Resume_clean']\n",
    "print(\"ðŸ“‹ Sample Resume (first 300 chars):\")\n",
    "print(sample_resume_text[:300])\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Find top 5 matching jobs\n",
    "top_jobs = find_top_k_jobs(\n",
    "    sample_resume_text, \n",
    "    jobs, \n",
    "    model, \n",
    "    tokenizer, \n",
    "    top_k=5,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "print(\"ðŸŽ¯ Top 5 Job Matches:\\n\")\n",
    "for idx, row in top_jobs.iterrows():\n",
    "    print(f\"Match Score: {row['match_score']:.4f}\")\n",
    "    if 'Title' in row:\n",
    "        print(f\"Title: {row['Title']}\")\n",
    "    print(f\"Preview: {row['job_preview']}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04158a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_top_k_accuracy(test_pairs, model, tokenizer, k_values=[1, 3, 5, 10]):\n",
    "    \"\"\"\n",
    "    Evaluate how often the true matching job appears in top-K recommendations\n",
    "    \"\"\"\n",
    "    from collections import defaultdict\n",
    "    \n",
    "    # Check if required columns exist\n",
    "    if 'resume_id' not in test_pairs.columns or 'job_id' not in test_pairs.columns:\n",
    "        print(\"âš ï¸ Warning: test_pairs missing 'resume_id' or 'job_id' columns\")\n",
    "        print(\"   Skipping top-K evaluation\")\n",
    "        return {}\n",
    "    \n",
    "    # Group by resume_id\n",
    "    resume_groups = test_pairs.groupby('resume_id')\n",
    "    \n",
    "    accuracies = defaultdict(list)\n",
    "    \n",
    "    print(f\"Evaluating top-K accuracy for {len(resume_groups)} unique resumes...\")\n",
    "    \n",
    "    for resume_id, group in tqdm(list(resume_groups.items())[:100]):  # Sample 100 for speed\n",
    "        try:\n",
    "            # Get resume text\n",
    "            resume_text = group.iloc[0]['resume_text']\n",
    "            \n",
    "            # Get true high-scoring jobs (top 25%)\n",
    "            threshold = group['label'].quantile(0.75)\n",
    "            true_good_jobs = set(group[group['label'] >= threshold]['job_id'])\n",
    "            \n",
    "            if not true_good_jobs:\n",
    "                continue\n",
    "            \n",
    "            # Create mini job dataframe from this group\n",
    "            mini_jobs = jobs.loc[group['job_id'].unique()].copy()\n",
    "            \n",
    "            if len(mini_jobs) < max(k_values):\n",
    "                continue\n",
    "            \n",
    "            # Get predictions\n",
    "            top_matches = find_top_k_jobs(\n",
    "                resume_text, \n",
    "                mini_jobs, \n",
    "                model, \n",
    "                tokenizer, \n",
    "                top_k=max(k_values),\n",
    "                batch_size=32\n",
    "            )\n",
    "            \n",
    "            # Check accuracy for each k\n",
    "            for k in k_values:\n",
    "                top_k_indices = set(top_matches.head(k).index)\n",
    "                hit = len(top_k_indices & true_good_jobs) > 0\n",
    "                accuracies[k].append(int(hit))\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Error processing resume {resume_id}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Calculate average accuracies\n",
    "    results = {k: np.mean(acc) if acc else 0.0 for k, acc in accuracies.items()}\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run evaluation (on subset for speed)\n",
    "try:\n",
    "    if 'resume_id' in training_pairs.columns and 'job_id' in training_pairs.columns:\n",
    "        print(\"ðŸ“Š Evaluating top-K accuracy...\")\n",
    "        k_accuracies = evaluate_top_k_accuracy(\n",
    "            training_pairs[training_pairs['resume_id'].isin(resumes['ID'].sample(min(50, len(resumes))).values)],\n",
    "            model,\n",
    "            tokenizer,\n",
    "            k_values=[1, 3, 5, 10]\n",
    "        )\n",
    "        \n",
    "        if k_accuracies:\n",
    "            print(\"\\nâœ… Top-K Accuracy Results:\")\n",
    "            for k, acc in k_accuracies.items():\n",
    "                print(f\"   Top-{k}: {acc:.2%}\")\n",
    "        else:\n",
    "            print(\"âš ï¸ No results from top-K evaluation\")\n",
    "    else:\n",
    "        print(\"âš ï¸ Skipping top-K evaluation (missing resume_id or job_id columns)\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Top-K evaluation failed: {e}\")\n",
    "    print(\"   This is optional - model training is complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ddefb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_and_recommend(resume_text, jobs_df, model_dir=MODEL_DIR, top_k=5):\n",
    "    \"\"\"\n",
    "    Convenience function to load model and get recommendations.\n",
    "    Use this in production/deployment.\n",
    "    \"\"\"\n",
    "    # Load model and tokenizer\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "    \n",
    "    # Get recommendations\n",
    "    return find_top_k_jobs(resume_text, jobs_df, model, tokenizer, top_k=top_k)\n",
    "\n",
    "print(\"âœ… Production-ready inference function defined\")\n",
    "print(f\"\\nTo use in production:\")\n",
    "print(f\"  from model_utils import load_model_and_recommend\")\n",
    "print(f\"  recommendations = load_model_and_recommend(resume_text, jobs_df, top_k=5)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
