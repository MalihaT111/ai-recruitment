{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "772946cd",
   "metadata": {},
   "source": [
    "# Prepare Training Data with Clustering Features\n",
    "\n",
    "This notebook integrates clustering results from notebooks 5, 6, and 7 with Jessica's scoring system to create a comprehensive training dataset for the AI recruitment model.\n",
    "\n",
    "## Objectives:\n",
    "1. Load clustered resume and job data from previous notebooks\n",
    "2. Merge cluster features (cluster ID, domain labels, PCA coordinates)\n",
    "3. Create cluster-based features (same_domain_cluster, cluster_distance)\n",
    "4. Integrate with Jessica's scoring metrics\n",
    "5. Save final training dataset with all features\n",
    "\n",
    "## Feature Set:\n",
    "- **Jessica's Scores**: skills, experience, education, semantic, domain\n",
    "- **Cluster Features**: resume cluster, job cluster, domain labels\n",
    "- **Derived Features**: same_domain_cluster, cluster_distance\n",
    "- **Labels**: Match quality (1 = good match, 0 = poor match)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47aab720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Imports & Setup\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Add utils to path\n",
    "sys.path.append(os.path.join(os.pardir, \"utils\"))\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure plotting\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "print(\"âœ… Libraries imported and environment configured\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d45db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Define Paths\n",
    "DATA_DIR = os.path.join(os.pardir, \"data\")\n",
    "EMB_DIR = os.path.join(DATA_DIR, \"embeddings\")\n",
    "\n",
    "# Clustered data from different notebooks\n",
    "resumes_hybrid_path = os.path.join(DATA_DIR, \"resumes_clustered_hybrid.csv\")  # from 5clustering\n",
    "jobs_hybrid_path = os.path.join(DATA_DIR, \"jobs_clustered_hybrid.csv\")        # from 5clustering\n",
    "resumes_semantic_path = os.path.join(DATA_DIR, \"resumes_clustered.csv\")       # from 6clustering\n",
    "\n",
    "# Embeddings\n",
    "resume_emb_path = os.path.join(EMB_DIR, \"resume_embeddings.npy\")\n",
    "job_emb_path = os.path.join(EMB_DIR, \"job_embeddings.npy\")\n",
    "\n",
    "# Verify paths exist\n",
    "for path in [resumes_hybrid_path, jobs_hybrid_path, resume_emb_path, job_emb_path]:\n",
    "    assert os.path.exists(path), f\"File not found: {path}\"\n",
    "\n",
    "print(\"âœ… All required files found\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bec9813",
   "metadata": {},
   "source": [
    "## Step 1: Load Clustered Data and Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afd8a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load clustered data\n",
    "resumes_clustered = pd.read_csv(resumes_hybrid_path)\n",
    "jobs_clustered = pd.read_csv(jobs_hybrid_path)\n",
    "\n",
    "# Load embeddings\n",
    "resume_embeddings = np.load(resume_emb_path)\n",
    "job_embeddings = np.load(job_emb_path)\n",
    "\n",
    "print(f\"Loaded {len(resumes_clustered)} resumes with {len(resumes_clustered.columns)} columns\")\n",
    "print(f\"Loaded {len(jobs_clustered)} jobs with {len(jobs_clustered.columns)} columns\")\n",
    "print(f\"\\nResume embeddings shape: {resume_embeddings.shape}\")\n",
    "print(f\"Job embeddings shape: {job_embeddings.shape}\")\n",
    "\n",
    "# Display available columns\n",
    "print(\"\\nðŸ“Š Resume columns:\", list(resumes_clustered.columns))\n",
    "print(\"\\nðŸ“Š Job columns:\", list(jobs_clustered.columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9149d811",
   "metadata": {},
   "source": [
    "## Step 2: Define Jessica's Scoring Functions\n",
    "\n",
    "These functions compute match scores based on:\n",
    "- **Skills**: Overlap between resume and job skills\n",
    "- **Experience**: Years of experience and seniority indicators\n",
    "- **Education**: Highest degree mentioned\n",
    "- **Domain**: Industry/field alignment\n",
    "- **Semantic**: Text similarity (will be replaced with embedding-based similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1130e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scoring configuration (from new.ipynb)\n",
    "import re\n",
    "\n",
    "# Feature weights\n",
    "weights = {\n",
    "    'skills': 0.35,\n",
    "    'experience': 0.20,\n",
    "    'education': 0.15,\n",
    "    'semantic': 0.15,\n",
    "    'domain': 0.15\n",
    "}\n",
    "\n",
    "# Skills keywords\n",
    "skills = ['excel', 'word', 'powerpoint', 'sql', 'python', 'project management', \n",
    "          'data analysis', 'ms office', 'microsoft office']\n",
    "\n",
    "# Education levels\n",
    "education_levels = {'phd': 4, 'master': 3, 'bachelor': 2, 'associate': 1, 'diploma': 0.5}\n",
    "\n",
    "# Experience indicators\n",
    "experience_words = ['manager', 'director', 'senior', 'lead', 'specialist', 'analyst']\n",
    "\n",
    "# Domain keywords (simplified for this example)\n",
    "domain_keywords = {\n",
    "    'hr': ['human resources', 'hr', 'recruitment', 'hiring', 'payroll', 'benefits'],\n",
    "    'finance': ['finance', 'accounting', 'budget', 'audit', 'tax', 'bookkeeping'],\n",
    "    'it': ['programming', 'software', 'python', 'java', 'sql', 'cloud', 'aws'],\n",
    "    'sales': ['sales', 'business development', 'crm', 'client', 'revenue'],\n",
    "    'administration': ['administrative', 'secretary', 'assistant', 'coordination'],\n",
    "    'research': ['research', 'analyst', 'analysis', 'data analysis', 'study']\n",
    "}\n",
    "\n",
    "print(\"âœ… Scoring configuration loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868d879c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scoring functions\n",
    "def calculate_skills_score(resume_text, job_text):\n",
    "    \"\"\"Calculate skill overlap between resume and job\"\"\"\n",
    "    resume_lower = str(resume_text).lower()\n",
    "    job_lower = str(job_text).lower()\n",
    "    job_skills = [skill for skill in skills if skill in job_lower]\n",
    "    if not job_skills:\n",
    "        return 0\n",
    "    resume_skills = [skill for skill in job_skills if skill in resume_lower]\n",
    "    return len(resume_skills) / len(job_skills)\n",
    "\n",
    "def calculate_experience_score(resume_text):\n",
    "    \"\"\"Estimate experience level from resume\"\"\"\n",
    "    text_lower = str(resume_text).lower()\n",
    "    years_matches = re.findall(r'(\\d+)\\s*(?:years?|yrs?)', text_lower)\n",
    "    max_years = max([int(year) for year in years_matches]) if years_matches else 0\n",
    "    exp_count = sum(1 for word in experience_words if word in text_lower)\n",
    "    return min((max_years / 10) + (exp_count / 5), 1.0)\n",
    "\n",
    "def calculate_education_score(resume_text):\n",
    "    \"\"\"Determine highest education level\"\"\"\n",
    "    text_lower = str(resume_text).lower()\n",
    "    max_education = 0\n",
    "    for level, score in education_levels.items():\n",
    "        if level in text_lower:\n",
    "            max_education = max(max_education, score)\n",
    "    return min(max_education / 4, 1.0)\n",
    "\n",
    "def calculate_domain_score(resume_text, job_text):\n",
    "    \"\"\"Check domain/industry alignment\"\"\"\n",
    "    resume_lower = str(resume_text).lower()\n",
    "    job_lower = str(job_text).lower()\n",
    "    job_domain = 'general'\n",
    "    max_domain_score = 0\n",
    "    for domain, keywords in domain_keywords.items():\n",
    "        domain_score = sum(1 for keyword in keywords if keyword in job_lower)\n",
    "        if domain_score > max_domain_score:\n",
    "            max_domain_score = domain_score\n",
    "            job_domain = domain\n",
    "    if job_domain == 'general':\n",
    "        return 0.5\n",
    "    domain_keywords_list = domain_keywords[job_domain]\n",
    "    matches = sum(1 for keyword in domain_keywords_list if keyword in resume_lower)\n",
    "    return min(matches / len(domain_keywords_list), 1.0)\n",
    "\n",
    "def calculate_semantic_score_embedding(resume_emb, job_emb):\n",
    "    \"\"\"Calculate semantic similarity using embeddings\"\"\"\n",
    "    return cosine_similarity([resume_emb], [job_emb])[0][0]\n",
    "\n",
    "def calculate_composite_score(resume_text, job_text, resume_emb, job_emb):\n",
    "    \"\"\"Compute weighted composite score with all components\"\"\"\n",
    "    scores = {\n",
    "        'skills': calculate_skills_score(resume_text, job_text),\n",
    "        'experience': calculate_experience_score(resume_text),\n",
    "        'education': calculate_education_score(resume_text),\n",
    "        'domain': calculate_domain_score(resume_text, job_text),\n",
    "        'semantic': calculate_semantic_score_embedding(resume_emb, job_emb)\n",
    "    }\n",
    "    final_score = sum(weights[component] * scores[component] for component in scores.keys())\n",
    "    return final_score, scores\n",
    "\n",
    "print(\"âœ… Scoring functions defined\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f394d192",
   "metadata": {},
   "source": [
    "## Step 3: Generate Resume-Job Pairs with Scores and Cluster Features\n",
    "\n",
    "For efficiency, we'll sample jobs and find top-matching resumes.\n",
    "We integrate:\n",
    "- Jessica's component scores (skills, experience, education, domain, semantic)\n",
    "- Cluster information (resume cluster, job cluster, domain labels)\n",
    "- Derived features (same_domain_cluster, cluster_distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe9d786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample jobs for efficiency (use all for production)\n",
    "N_JOBS_SAMPLE = 100  # Adjust as needed\n",
    "job_sample = jobs_clustered.head(N_JOBS_SAMPLE).reset_index(drop=True)\n",
    "\n",
    "print(f\"Processing {len(job_sample)} jobs...\")\n",
    "\n",
    "training_pairs = []\n",
    "\n",
    "for job_idx, job_row in job_sample.iterrows():\n",
    "    if job_idx % 20 == 0:\n",
    "        print(f\"Processing job {job_idx}/{len(job_sample)}...\")\n",
    "    \n",
    "    job_text = job_row['job_text_clean']\n",
    "    job_cluster = job_row['cluster'] if 'cluster' in job_row else job_row.get('PredictedCluster')\n",
    "    job_domain_label = job_row.get('JobClusterDomainLabel', 'Unknown')\n",
    "    job_emb = job_embeddings[job_idx]\n",
    "    \n",
    "    resume_results = []\n",
    "    \n",
    "    for resume_idx, resume_row in resumes_clustered.iterrows():\n",
    "        resume_text = resume_row.get('Resume_clean', '')\n",
    "        resume_id = resume_row.get('ID', resume_idx)\n",
    "        resume_cluster = resume_row['cluster'] if 'cluster' in resume_row else resume_row.get('PredictedCluster')\n",
    "        resume_domain_label = resume_row.get('ClusterDomainLabel', 'Unknown')\n",
    "        resume_emb = resume_embeddings[resume_idx]\n",
    "        \n",
    "        # Calculate scores\n",
    "        final_score, component_scores = calculate_composite_score(\n",
    "            resume_text, job_text, resume_emb, job_emb\n",
    "        )\n",
    "        \n",
    "        # Cluster features\n",
    "        same_domain_cluster = int(resume_domain_label == job_domain_label)\n",
    "        cluster_distance = abs((resume_cluster or 0) - (job_cluster or 0))\n",
    "        \n",
    "        resume_results.append({\n",
    "            'job_idx': job_idx,\n",
    "            'resume_idx': resume_idx,\n",
    "            'resume_id': resume_id,\n",
    "            'resume_cluster': resume_cluster,\n",
    "            'resume_domain_label': resume_domain_label,\n",
    "            'job_cluster': job_cluster,\n",
    "            'job_domain_label': job_domain_label,\n",
    "            'same_domain_cluster': same_domain_cluster,\n",
    "            'cluster_distance': cluster_distance,\n",
    "            'final_score': final_score,\n",
    "            **component_scores  # Unpack all component scores\n",
    "        })\n",
    "    \n",
    "    # Keep top 10 matches per job\n",
    "    resume_results.sort(key=lambda x: x['final_score'], reverse=True)\n",
    "    training_pairs.extend(resume_results[:10])\n",
    "\n",
    "# Convert to DataFrame\n",
    "training_data = pd.DataFrame(training_pairs)\n",
    "\n",
    "print(f\"\\nâœ… Generated {len(training_data)} training pairs\")\n",
    "print(f\"Columns: {list(training_data.columns)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a1d7ab",
   "metadata": {},
   "source": [
    "## Step 4: Create Labels Based on Score Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c04c806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create labels using quartiles\n",
    "scores = training_data['final_score']\n",
    "high_threshold = scores.quantile(0.75)\n",
    "low_threshold = scores.quantile(0.25)\n",
    "\n",
    "print(f\"Score thresholds: High={high_threshold:.3f}, Low={low_threshold:.3f}\")\n",
    "\n",
    "# Assign labels\n",
    "def assign_label(score):\n",
    "    if score >= high_threshold:\n",
    "        return 1  # Good match\n",
    "    elif score <= low_threshold:\n",
    "        return 0  # Poor match\n",
    "    else:\n",
    "        return -1  # Ambiguous (will be filtered)\n",
    "\n",
    "training_data['label'] = training_data['final_score'].apply(assign_label)\n",
    "\n",
    "# Filter out ambiguous cases\n",
    "labeled_training_data = training_data[training_data['label'] != -1].copy()\n",
    "\n",
    "print(f\"\\nâœ… Labeled dataset created\")\n",
    "print(f\"Total pairs: {len(labeled_training_data)}\")\n",
    "print(f\"Good matches (1): {(labeled_training_data['label'] == 1).sum()}\")\n",
    "print(f\"Poor matches (0): {(labeled_training_data['label'] == 0).sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee81a928",
   "metadata": {},
   "source": [
    "## Step 5: Analyze Feature Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43614bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize score distribution\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# Final score distribution\n",
    "axes[0, 0].hist(labeled_training_data['final_score'], bins=30, color='skyblue', edgecolor='black')\n",
    "axes[0, 0].set_title('Final Score Distribution')\n",
    "axes[0, 0].set_xlabel('Score')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Component scores\n",
    "component_names = ['skills', 'experience', 'education', 'domain', 'semantic']\n",
    "for idx, component in enumerate(component_names):\n",
    "    row = (idx + 1) // 3\n",
    "    col = (idx + 1) % 3\n",
    "    axes[row, col].hist(labeled_training_data[component], bins=20, color='salmon', edgecolor='black')\n",
    "    axes[row, col].set_title(f'{component.capitalize()} Score')\n",
    "    axes[row, col].set_xlabel('Score')\n",
    "    axes[row, col].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30be6f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze cluster features\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Same domain cluster vs label\n",
    "same_domain_by_label = labeled_training_data.groupby('label')['same_domain_cluster'].mean()\n",
    "axes[0].bar(['Poor Match (0)', 'Good Match (1)'], same_domain_by_label.values, color=['coral', 'lightgreen'])\n",
    "axes[0].set_title('Same Domain Cluster Rate by Match Quality')\n",
    "axes[0].set_ylabel('Proportion')\n",
    "axes[0].set_ylim([0, 1])\n",
    "\n",
    "# Cluster distance vs label\n",
    "cluster_dist_by_label = labeled_training_data.groupby('label')['cluster_distance'].mean()\n",
    "axes[1].bar(['Poor Match (0)', 'Good Match (1)'], cluster_dist_by_label.values, color=['coral', 'lightgreen'])\n",
    "axes[1].set_title('Average Cluster Distance by Match Quality')\n",
    "axes[1].set_ylabel('Distance')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ“Š Cluster Feature Analysis:\")\n",
    "print(f\"Same domain cluster rate for good matches: {same_domain_by_label.get(1, 0):.2%}\")\n",
    "print(f\"Same domain cluster rate for poor matches: {same_domain_by_label.get(0, 0):.2%}\")\n",
    "print(f\"Avg cluster distance for good matches: {cluster_dist_by_label.get(1, 0):.2f}\")\n",
    "print(f\"Avg cluster distance for poor matches: {cluster_dist_by_label.get(0, 0):.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514b26a8",
   "metadata": {},
   "source": [
    "## Step 6: Save Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7839b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final training dataset\n",
    "output_path = os.path.join(DATA_DIR, \"training_data_with_clusters.csv\")\n",
    "labeled_training_data.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"âœ… Saved training data to: {output_path}\")\n",
    "print(f\"\\nðŸ“Š Final Dataset Summary:\")\n",
    "print(f\"Total samples: {len(labeled_training_data)}\")\n",
    "print(f\"Features: {len(labeled_training_data.columns)}\")\n",
    "print(f\"\\nColumn list:\")\n",
    "for col in labeled_training_data.columns:\n",
    "    print(f\"  - {col}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03a9dd4",
   "metadata": {},
   "source": [
    "## Step 7: Preview Sample Matches\n",
    "\n",
    "Let's look at some example good and poor matches to validate the scoring system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe7e40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a few examples\n",
    "print(\"\\nTop 3 good matches:\")\n",
    "print(labeled_training_data.sort_values('final_score', ascending=False).head(3)[\n",
    "    ['resume_id', 'resume_domain_label', 'job_domain_label', 'final_score', 'skills', 'semantic']\n",
    "])\n",
    "\n",
    "print(\"\\nTop 3 poor matches:\")\n",
    "print(labeled_training_data.sort_values('final_score', ascending=True).head(3)[\n",
    "    ['resume_id', 'resume_domain_label', 'job_domain_label', 'final_score', 'skills', 'semantic']\n",
    "])\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
