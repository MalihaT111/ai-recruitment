{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Imports & Paths\n",
    "import importlib.util\n",
    "\n",
    "import os, sys, re, pandas as pd\n",
    "sys.path.append(os.path.join(os.pardir, \"utils\"))\n",
    "\n",
    "DATA_DIR = os.path.join(os.pardir, \"data\")\n",
    "resume_path = os.path.join(DATA_DIR, \"resumes_cleaned.csv\")\n",
    "jobs_path   = os.path.join(DATA_DIR, \"jobs_cleaned.csv\")\n",
    "\n",
    "\n",
    "EMB_DIR = os.path.join(os.pardir, \"data/embeddings\")\n",
    "remb_path = os.path.join(EMB_DIR, \"resume_embeddings.npy\")\n",
    "jemb_path   = os.path.join(EMB_DIR, \"job_embeddings.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7clustering.ipynb ‚Äî Resume‚ÄìJob Domain Alignment + Visualization + Matching\n",
    "\n",
    "# =============================================\n",
    "# 1Ô∏è‚É£ Imports & Paths\n",
    "# =============================================\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "\n",
    "# Define paths\n",
    "DATA_DIR = os.path.join(os.pardir, 'data')\n",
    "EMB_DIR = os.path.join(DATA_DIR, 'embeddings')\n",
    "\n",
    "resume_path = os.path.join(DATA_DIR, 'resumes_clustered.csv')\n",
    "jobs_path   = os.path.join(DATA_DIR, 'jobs_cleaned.csv')\n",
    "remb_path   = os.path.join(EMB_DIR, 'resume_embeddings.npy')\n",
    "jemb_path   = os.path.join(EMB_DIR, 'job_embeddings.npy')\n",
    "\n",
    "# =============================================\n",
    "# 2Ô∏è‚É£ Load Data and Embeddings\n",
    "# =============================================\n",
    "resumes = pd.read_csv(resume_path)\n",
    "jobs = pd.read_csv(jobs_path)\n",
    "\n",
    "resume_emb = np.load(remb_path)\n",
    "job_emb = np.load(jemb_path)\n",
    "\n",
    "print(f\"Loaded {len(resumes)} resumes and {len(jobs)} job posts.\")\n",
    "\n",
    "# =============================================\n",
    "# 3Ô∏è‚É£ K-Means Clustering for Job Embeddings\n",
    "# =============================================\n",
    "n_clusters = 12\n",
    "job_kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "jobs['PredictedCluster'] = job_kmeans.fit_predict(job_emb)\n",
    "\n",
    "# =============================================\n",
    "# 4Ô∏è‚É£ Keyword-Based Domain Labeling for Jobs\n",
    "# =============================================\n",
    "# def infer_keyword_domain(text, keywords_dict):\n",
    "#     text = str(text).lower()\n",
    "#     scores = {domain: sum(kw in text for kw in kws) for domain, kws in keywords_dict.items()}\n",
    "#     return max(scores, key=scores.get) if scores else 'Unknown'\n",
    "\n",
    "jobs['KeywordDomain'] = jobs['job_text_clean'].apply(lambda t: infer_keyword_domain(t, DOMAIN_KEYWORDS_REFERENCE))\n",
    "\n",
    "# Assign cluster-level domain labels\n",
    "cluster_labels = {}\n",
    "for cid, group in jobs.groupby('PredictedCluster'):\n",
    "    top_label = group['KeywordDomain'].value_counts().idxmax()\n",
    "    cluster_labels[cid] = top_label\n",
    "\n",
    "jobs['JobClusterDomainLabel'] = jobs['PredictedCluster'].map(cluster_labels)\n",
    "\n",
    "# =============================================\n",
    "# 5Ô∏è‚É£ Compute Cross-Domain Similarity\n",
    "# =============================================\n",
    "resume_domains = resumes['ClusterDomainLabel'].unique()\n",
    "job_domains = jobs['JobClusterDomainLabel'].unique()\n",
    "\n",
    "resume_centroids = []\n",
    "for domain in resume_domains:\n",
    "    cluster_vectors = resume_emb[resumes['ClusterDomainLabel'] == domain]\n",
    "    resume_centroids.append(cluster_vectors.mean(axis=0))\n",
    "\n",
    "job_centroids = []\n",
    "for domain in job_domains:\n",
    "    cluster_vectors = job_emb[jobs['JobClusterDomainLabel'] == domain]\n",
    "    job_centroids.append(cluster_vectors.mean(axis=0))\n",
    "\n",
    "similarity = cosine_similarity(resume_centroids, job_centroids)\n",
    "\n",
    "# =============================================\n",
    "# 6Ô∏è‚É£ Visualize Cross-Domain Alignment (Heatmap)\n",
    "# =============================================\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(similarity, annot=True, fmt='.2f', cmap='YlGnBu',\n",
    "            xticklabels=job_domains, yticklabels=resume_domains)\n",
    "plt.title('Resume‚ÄìJob Domain Similarity (Cosine)')\n",
    "plt.xlabel('Job Domains')\n",
    "plt.ylabel('Resume Domains')\n",
    "plt.show()\n",
    "\n",
    "# =============================================\n",
    "# 7Ô∏è‚É£ Visualization: Top 3 Matches per Resume Domain (Bar Chart)\n",
    "# =============================================\n",
    "summary_data = []\n",
    "for i, resume_domain in enumerate(resume_domains):\n",
    "    sims = similarity[i]\n",
    "    sorted_idx = np.argsort(sims)[::-1][:3]\n",
    "    top_matches = [(job_domains[j], sims[j]) for j in sorted_idx]\n",
    "    for job_dom, score in top_matches:\n",
    "        summary_data.append((resume_domain, job_dom, score))\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data, columns=['ResumeDomain', 'JobDomain', 'Similarity'])\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(data=summary_df, x='ResumeDomain', y='Similarity', hue='JobDomain', palette='Set2')\n",
    "plt.title('Top 3 Matching Job Domains for Each Resume Domain')\n",
    "plt.ylabel('Cosine Similarity')\n",
    "plt.ylim(0.6, 1.0)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# =============================================\n",
    "# 8Ô∏è‚É£ Text Summary of Domain Alignment\n",
    "# =============================================\n",
    "for i, resume_domain in enumerate(resume_domains):\n",
    "    top_idx = np.argmax(similarity[i])\n",
    "    best_match = job_domains[top_idx]\n",
    "    score = similarity[i, top_idx]\n",
    "    second_idx = np.argsort(similarity[i])[-2]\n",
    "    second_best = job_domains[second_idx]\n",
    "    second_score = similarity[i, second_idx]\n",
    "    print(f\"{resume_domain} resumes best match {best_match} jobs (similarity={score:.3f}), followed by {second_best} ({second_score:.3f}).\")\n",
    "\n",
    "# =============================================\n",
    "# 9Ô∏è‚É£ Individual Resume‚ÜíJob Matching\n",
    "# =============================================\n",
    "# For each resume vector, find the closest job cluster centroid\n",
    "resume_to_job = []\n",
    "for idx, vec in enumerate(resume_emb):\n",
    "    sims = cosine_similarity([vec], job_centroids)[0]\n",
    "    top_idx = np.argmax(sims)\n",
    "    best_job_domain = job_domains[top_idx]\n",
    "    score = sims[top_idx]\n",
    "    resume_to_job.append((idx, resumes.loc[idx, 'ClusterDomainLabel'], best_job_domain, score))\n",
    "\n",
    "match_df = pd.DataFrame(resume_to_job, columns=['ResumeIndex', 'ResumeDomain', 'MatchedJobDomain', 'Similarity'])\n",
    "\n",
    "# Save the mapping\n",
    "match_out_path = os.path.join(DATA_DIR, 'resume_job_matches.csv')\n",
    "match_df.to_csv(match_out_path, index=False)\n",
    "print(f'‚úÖ Saved individual resume‚Üíjob domain matches to {match_out_path}')\n",
    "\n",
    "# =============================================\n",
    "# üîö Summary\n",
    "# =============================================\n",
    "print(\"\\nPipeline complete:\")\n",
    "print(\"1. Generated job domain clusters.\")\n",
    "print(\"2. Compared resume‚Üîjob semantic centroids (heatmap + bar chart).\")\n",
    "print(\"3. Saved per-resume best job domain matches for future analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = pd.read_csv(\"../data/resume_job_matches.csv\")\n",
    "matches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0  # change this number to see other examples\n",
    "\n",
    "resume_text = resumes.loc[idx, \"Resume_clean\"]\n",
    "resume_domain = matches.loc[idx, \"ResumeDomain\"]\n",
    "job_domain = matches.loc[idx, \"MatchedJobDomain\"]\n",
    "\n",
    "print(f\"Resume Domain: {resume_domain}\")\n",
    "print(f\"Matched Job Domain: {job_domain}\")\n",
    "print(\"---- Resume ----\")\n",
    "print(resume_text[:600])  # show first 600 chars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for domain_name in DOMAIN_KEYWORDS_REFERENCE.keys():\n",
    "    keywords = DOMAIN_KEYWORDS_REFERENCE[domain_name]\n",
    "    pattern = \"|\".join([r\"\\b\" + kw + r\"\\b\" for kw in keywords])\n",
    "    keyword_matches = jobs[jobs['job_text_clean'].str.contains(pattern, case=False, na=False, regex=True)]\n",
    "\n",
    "    \n",
    "    if not keyword_matches.empty:\n",
    "        print(f\"\\n---- Matching Job Posting for {domain_name} ----\")\n",
    "        print(keyword_matches.iloc[0]['job_text_clean'][:600])\n",
    "    else:\n",
    "        print(f\"\\nNo matching job posting found for {domain_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show top 5 strongest matches overall\n",
    "top_matches = match_df.sort_values('Similarity', ascending=False).head(5)\n",
    "\n",
    "for _, row in top_matches.iterrows():\n",
    "    r_idx = row['ResumeIndex']\n",
    "    resume_text = resumes.loc[r_idx, \"Resume_clean\"][:400]\n",
    "\n",
    "    job_domain = row['MatchedJobDomain']\n",
    "    job_match = jobs[jobs[\"JobClusterDomainLabel\"] == job_domain].sample(1, random_state=42)\n",
    "    job_text = job_match.iloc[0][\"job_text_clean\"][:400]\n",
    "\n",
    "    print(f\"\\nResume #{r_idx} ‚Äî {row['ResumeDomain']} ‚Üí {job_domain} (Similarity: {row['Similarity']:.3f})\")\n",
    "    print(\"-\" * 90)\n",
    "    print(\"Resume snippet:\")\n",
    "    print(resume_text)\n",
    "    print()\n",
    "    print(\"Matched job posting snippet:\")\n",
    "    print(job_text)\n",
    "    print(\"=\" * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================\n",
    "# üîé Inspect Sample Resume‚ÄìJob Matches\n",
    "# =============================================\n",
    "\n",
    "# sample 5 resume‚Äìjob pairs\n",
    "sample = match_df.sample(5, random_state=42)\n",
    "\n",
    "for _, row in sample.iterrows():\n",
    "    r_idx = row['ResumeIndex']\n",
    "    \n",
    "    # get the resume text\n",
    "    resume_text = resumes.loc[r_idx, \"Resume_clean\"][:400]\n",
    "    \n",
    "    # find a matching job posting in that matched job domain\n",
    "    job_domain = row['MatchedJobDomain']\n",
    "    job_matches = jobs[jobs[\"JobClusterDomainLabel\"] == job_domain]\n",
    "    \n",
    "    if not job_matches.empty:\n",
    "        job_text = job_matches.sample(1, random_state=42).iloc[0][\"job_text_clean\"][:400]\n",
    "    else:\n",
    "        job_text = \"[No job text found for this domain]\"\n",
    "    \n",
    "    print(f\"\\nResume #{r_idx} ‚Äî {row['ResumeDomain']} ‚Üí {job_domain} (Similarity: {row['Similarity']:.3f})\")\n",
    "    print(\"-\" * 90)\n",
    "    print(\"Resume snippet:\")\n",
    "    print(resume_text)\n",
    "    print()\n",
    "    print(\"Matched job posting snippet:\")\n",
    "    print(job_text)\n",
    "    print(\"=\" * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(matches.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
